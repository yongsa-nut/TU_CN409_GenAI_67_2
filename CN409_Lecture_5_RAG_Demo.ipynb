{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMplY4TDQzR6wQg6I1nbIAK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yongsa-nut/TU_CN409_GenAI_67_2/blob/main/CN409_Lecture_5_RAG_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CN 409 - Lecture 5: RAG Demo"
      ],
      "metadata": {
        "id": "lR6f0qCXKX0o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up LLM"
      ],
      "metadata": {
        "id": "NO9W08JgLcSl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gemini version"
      ],
      "metadata": {
        "id": "I_HFwdyS84VN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am6p18vO8uMY",
        "outputId": "2b4d2530-02d2-4441-db2a-df2368562925"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/130.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m122.9/130.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.7/130.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth application-default login"
      ],
      "metadata": {
        "id": "rCqhcoBw8sAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth application-default set-quota-project cn409-genai-672 # replace the last one with your project ID"
      ],
      "metadata": {
        "id": "pqiTYMdy9jUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google import genai\n",
        "\n",
        "PROJECT_ID = \"cn409-genai-672\"\n",
        "\n",
        "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
        "\n",
        "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "pfDlAJTh9xuO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(prompt):\n",
        "  # This can be any LLM for this lecture\n",
        "  response = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash-001\", contents=prompt\n",
        "  )\n",
        "  return response.text\n",
        "\n",
        "print(generate(\"Hello\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDcKbot69te7",
        "outputId": "dbc31d5d-4722-4062-a08e-8c1abd8e44c9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I help you today?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "## Demo 1: Keyword Matching"
      ],
      "metadata": {
        "id": "RCHIjOUTLfUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The data\n",
        "lorebook = { 'ตึกวิจัย' : 'ตำแหน่ง latitude = 14.0694899, longitude = 100.6050282',\n",
        "             'ตึกอำนวยการ' : 'ตำแหน่ง latitude = 14.0690024, longitude = 100.6061611'\n",
        "}"
      ],
      "metadata": {
        "id": "KR6PDnuTLqPl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def keyword_generate(query, docs):\n",
        "  # Retrive information and create context\n",
        "  context = '<context>'\n",
        "  for k in docs:\n",
        "    if k in query:\n",
        "      context += f'{k} = {docs[k]}\\n'\n",
        "  context += '</context>'\n",
        "\n",
        "  prompt = f'''<question>{query}</question>\n",
        "  Please use context in <context> tags to answer the question.\n",
        "  <context>{context}</context>'''\n",
        "  response = generate(prompt)\n",
        "  # printing out\n",
        "  print('Query:', query)\n",
        "  print('Retrieved documents:', context)\n",
        "  print('Response:', response)\n",
        "\n",
        "query = 'ตึกวิจัยอยู่ไหน?'\n",
        "\n",
        "keyword_generate(query, lorebook)"
      ],
      "metadata": {
        "id": "Oh9tZBohNMy-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acedc08e-30a5-4beb-8d21-dea4d3433d51"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: ตึกวิจัยอยู่ไหน?\n",
            "Retrieved documents: <context>ตึกวิจัย = ตำแหน่ง latitude = 14.0694899, longitude = 100.6050282\n",
            "</context>\n",
            "Response: ตึกวิจัยอยู่ที่ตำแหน่ง latitude 14.0694899, longitude 100.6050282\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "## Demo 2: BM25"
      ],
      "metadata": {
        "id": "d4YUIn8vQUsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install rank_bm25"
      ],
      "metadata": {
        "id": "SeGE2QcJc5P9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rank_bm25 import BM25Okapi"
      ],
      "metadata": {
        "id": "bLLcL3dGQXO7"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample document collection\n",
        "documents = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"A journey of a thousand miles begins with a single step.\",\n",
        "    \"To be or not to be, that is the question.\",\n",
        "    \"All that glitters is not gold.\",\n",
        "    \"Where there's smoke, there's fire.\",\n",
        "    \"The early bird catches the worm.\",\n",
        "    \"Actions speak louder than words.\",\n",
        "    \"Knowledge is power, but enthusiasm pulls the switch.\",\n",
        "    \"The pen is mightier than the sword.\",\n",
        "    \"When life gives you lemons, make lemonade.\"\n",
        "]\n",
        "\n",
        "# Simple tokenization using string splitting\n",
        "tokenized_docs = [doc.lower().split() for doc in documents]\n",
        "\n",
        "# Create BM25 object\n",
        "bm25 = BM25Okapi(tokenized_docs)"
      ],
      "metadata": {
        "id": "4yfWslkwdZ-p"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve(query, top_k=2):\n",
        "  # Words only\n",
        "  tokenized_query = query.lower().split()\n",
        "  # Pass the list of words into bm25 to get scores\n",
        "  doc_scores = bm25.get_scores(tokenized_query)\n",
        "  # Then retrieve the score\n",
        "  top_docs = sorted(enumerate(doc_scores), key=lambda x: x[1], reverse=True)[:top_k]\n",
        "\n",
        "  return [documents[i] for i, _ in top_docs]"
      ],
      "metadata": {
        "id": "QRjJv2O5dvwb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bm25_response(query):\n",
        "  retrieved_docs = retrieve(query)\n",
        "  context = \"\\n\".join(retrieved_docs)\n",
        "\n",
        "  prompt = f'''<question>{query}</question>\n",
        "  Please use context in <context> tags to answr the question.\n",
        "  <context>{context}</context>'''\n",
        "  response = generate(prompt)\n",
        "  # printing out\n",
        "  print('Query:', query)\n",
        "  print('Retrieved documents:', retrieved_docs)\n",
        "  print('Response:', response)\n",
        "\n",
        "query = \"What jumps over the dog?\"\n",
        "bm25_response(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jclDtDltd2aX",
        "outputId": "7c05f6e0-55de-4462-c14a-fcd52363de45"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What jumps over the dog?\n",
            "Retrieved documents: ['The quick brown fox jumps over the lazy dog.', 'A journey of a thousand miles begins with a single step.']\n",
            "Response: The quick brown fox jumps over the dog.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "## Demo 3: RAG without actual database"
      ],
      "metadata": {
        "id": "9OKu_c9XQXg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers datasets"
      ],
      "metadata": {
        "id": "WBgAHs-G2rxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "EeZPGTOglxCS"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Same document collection\n",
        "documents = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"A journey of a thousand miles begins with a single step.\",\n",
        "    \"To be or not to be, that is the question.\",\n",
        "    \"All that glitters is not gold.\",\n",
        "    \"Where there's smoke, there's fire.\",\n",
        "    \"The early bird catches the worm.\",\n",
        "    \"Actions speak louder than words.\",\n",
        "    \"Knowledge is power, but enthusiasm pulls the switch.\",\n",
        "    \"The pen is mightier than the sword.\",\n",
        "    \"When life gives you lemons, make lemonade.\"\n",
        "]\n",
        "\n",
        "# Initialize sentence transformer model\n",
        "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Embed documents\n",
        "doc_embeddings = embed_model.encode(documents)"
      ],
      "metadata": {
        "id": "cdMfAmJiQb_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_embeddings"
      ],
      "metadata": {
        "id": "7dteCYnrD54u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(doc_embeddings[0])"
      ],
      "metadata": {
        "id": "dcsDYhKnD-0u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec13df9e-518c-46ef-f9af-d10c36a05e4a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "384"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_RAG_docs(query, top_k=1):\n",
        "    # Embed the query\n",
        "    query_embedding = embed_model.encode([query])\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    similarities = cosine_similarity(query_embedding, doc_embeddings)[0]\n",
        "\n",
        "    # Get top-k relevant documents\n",
        "    top_indices = similarities.argsort()[-top_k:][::-1]\n",
        "    return [documents[i] for i in top_indices]"
      ],
      "metadata": {
        "id": "gJeYSxVXl4p8"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def RAG_response(query, top_k=3):\n",
        "  retrieved_docs = retrieve_RAG_docs(query, top_k)\n",
        "  context = \"\\n\".join(retrieved_docs)\n",
        "\n",
        "  prompt = f'''<question>{query}</question>\n",
        "  Please use context in <context> tags to answr the question.\n",
        "  <context>{context}</context>'''\n",
        "  response = generate(prompt)\n",
        "  # printing out\n",
        "  print('Query:', query)\n",
        "  print('Retrieved documents:', retrieved_docs)\n",
        "  print('Response:', response)\n",
        "\n",
        "query = \"What jumps over the dog?\"\n",
        "RAG_response(query)"
      ],
      "metadata": {
        "id": "PMjsoZmGl-4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "## Demo 4: RAG with Pinecone"
      ],
      "metadata": {
        "id": "3xFmli7GHKNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pinecone"
      ],
      "metadata": {
        "id": "DcvarCOIHOri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone, ServerlessSpec"
      ],
      "metadata": {
        "id": "O01aRLUcHPxv"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "if device != 'cuda':\n",
        "    print('Sorry no cuda.')\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)"
      ],
      "metadata": {
        "id": "7bN7jN1EHTFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'What jumps over the dog?'\n",
        "xq = model.encode(query)\n",
        "xq.shape"
      ],
      "metadata": {
        "id": "IL2GZ9lbHWwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Same document collection\n",
        "documents = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"A journey of a thousand miles begins with a single step.\",\n",
        "    \"To be or not to be, that is the question.\",\n",
        "    \"All that glitters is not gold.\",\n",
        "    \"Where there's smoke, there's fire.\",\n",
        "    \"The early bird catches the worm.\",\n",
        "    \"Actions speak louder than words.\",\n",
        "    \"Knowledge is power, but enthusiasm pulls the switch.\",\n",
        "    \"The pen is mightier than the sword.\",\n",
        "    \"When life gives you lemons, make lemonade.\"\n",
        "]\n",
        "\n",
        "doc_embeddings = embed_model.encode(documents)"
      ],
      "metadata": {
        "id": "2wfKlSD-Hery"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Pinecone"
      ],
      "metadata": {
        "id": "ZzxE0W-KHaIW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get secret key\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "5u_ryrakNHC8"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone = Pinecone(api_key=userdata.get('pinecone_key'))\n",
        "INDEX_NAME = 'test1-2-16-2025'\n",
        "\n",
        "# Cleaning up the index\n",
        "if INDEX_NAME in [index.name for index in pinecone.list_indexes()]:\n",
        "    pinecone.delete_index(INDEX_NAME)\n",
        "print(INDEX_NAME)\n",
        "\n",
        "# Creating a serverless index\n",
        "pinecone.create_index(\n",
        "    name = INDEX_NAME,\n",
        "    dimension = model.get_sentence_embedding_dimension(),\n",
        "    metric = 'cosine',\n",
        "    spec = ServerlessSpec(cloud='aws', region='us-east-1')) #\n",
        "\n",
        "index = pinecone.Index(INDEX_NAME)\n",
        "print(index)"
      ],
      "metadata": {
        "id": "WnujxL-7HaIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Upsert to Pinecone\n",
        "\n",
        "- Format: A list of dict\n",
        "  - `{'id':xx, 'value':embedding, 'metadata':dict}`\n",
        "- Document: https://docs.pinecone.io/reference/api/2024-07/data-plane/upsert"
      ],
      "metadata": {
        "id": "G7q4_ScGHpq_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create id\n",
        "ids = [str(x) for x in range(len(documents))]\n",
        "# Create metadata\n",
        "metadatas = [{'text': text} for text in documents]\n",
        "# Zip them together\n",
        "records = zip(ids, doc_embeddings, metadatas)\n",
        "index.upsert(vectors=records)   # There is a limit on how much you can upsert at a time. See https://docs.pinecone.io/guides/data/upsert-data"
      ],
      "metadata": {
        "id": "XdWVB_pYHsJD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53eaf222-c8b1-43bf-c98d-2149d60603fa"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'upserted_count': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index.describe_index_stats()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gkXZ3xrIHysW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4c7c56b-05d5-403b-f63d-4b14e5683e8e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 384,\n",
              " 'index_fullness': 0.0,\n",
              " 'metric': 'cosine',\n",
              " 'namespaces': {},\n",
              " 'total_vector_count': 0,\n",
              " 'vector_type': 'dense'}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retriving Documents\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U2W1fv5UKhHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'What jumps over the dog?'\n",
        "\n",
        "# 1) Embedding your query\n",
        "embed_query = model.encode(query).tolist()\n",
        "retrieved_docs =  index.query(vector=embed_query, top_k=1, include_metadata=True)\n",
        "print(retrieved_docs)"
      ],
      "metadata": {
        "id": "f9mGia8pKg1_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ccd55a0-08c1-4bc3-d150-9b920323cff1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'matches': [], 'namespace': '', 'usage': {'read_units': 1}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = [r['metadata']['text'] for r in retrieved_docs['matches']]\n",
        "print(text)"
      ],
      "metadata": {
        "id": "P5srP5e2L5q5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca90b5cd-77c3-48ce-eb54-cc021a7816d5"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate with retrived documents"
      ],
      "metadata": {
        "id": "wPdaAuH0KkDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RAG_pinecone_response(query, top_k=1):\n",
        "  # First embedding your query\n",
        "  embed_query = model.encode(query).tolist()\n",
        "  # Then retrieve the document\n",
        "  retrieved_docs =  index.query(vector=embed_query,\n",
        "                                top_k=top_k,\n",
        "                                include_metadata=True)\n",
        "  # Then get the actual text\n",
        "  text = [r['metadata']['text'] for r in retrieved_docs['matches']]\n",
        "  # Finally join them together\n",
        "  context = \"\\n\".join(text)\n",
        "\n",
        "  prompt = f'''<question>{query}</question>\n",
        "  Please use context in <context> tags to answr the question.\n",
        "  <context>{context}</context>'''\n",
        "  response = generate(prompt)\n",
        "  # printing out\n",
        "  print('Query:', query)\n",
        "  print('Retrieved documents:', text)\n",
        "  print('Response:', response)\n",
        "\n",
        "query = 'What jumps over the dog?'\n",
        "RAG_pinecone_response(query)"
      ],
      "metadata": {
        "id": "llnGF5A5Kd4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9ce8bd7-77eb-4a4e-9d6f-9feca19dfc55"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What jumps over the dog?\n",
            "Retrieved documents: []\n",
            "Response: Without any context, the most common and playful answer to \"What jumps over the dog?\" is:\n",
            "\n",
            "A cat.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "### Demo 5: Search with Pinecone\n",
        "- Code snippet from https://learn.deeplearning.ai/courses/building-applications-vector-databases/lesson/1/introduction"
      ],
      "metadata": {
        "id": "BCvUUdKfQcS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset   # From Huggingface. Need Hugging face token. Here: https://huggingface.co/docs/hub/en/security-tokens\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import os\n",
        "import time\n",
        "import torch"
      ],
      "metadata": {
        "id": "zAU3K2Eg2J9J"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset('quora', split='train[240000:290000]')"
      ],
      "metadata": {
        "id": "jrml7Dc43fOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[:5]"
      ],
      "metadata": {
        "id": "WqXlDdDO3Dtw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions = []\n",
        "for record in dataset['questions']:\n",
        "    questions.extend(record['text'])\n",
        "question = list(set(questions))\n",
        "print('\\n'.join(questions[:10]))\n",
        "print('-' * 50)\n",
        "print(f'Number of questions: {len(questions)}')"
      ],
      "metadata": {
        "id": "eAanDNin3jQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Check cuda and Setup the model"
      ],
      "metadata": {
        "id": "o1dn48Gu3rlO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "if device != 'cuda':\n",
        "    print('Sorry no cuda.')\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)"
      ],
      "metadata": {
        "id": "v3Rtpykn3rKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'which city is the most populated in the world?'\n",
        "xq = model.encode(query)\n",
        "xq.shape"
      ],
      "metadata": {
        "id": "9HxVO4In3ztc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Pinecone"
      ],
      "metadata": {
        "id": "_YftDeaa4DHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone = Pinecone(api_key=userdata.get('pinecone_key'))\n",
        "INDEX_NAME = 'test1-16-2-2025'\n",
        "\n",
        "# Cleaning up the index\n",
        "if INDEX_NAME in [index.name for index in pinecone.list_indexes()]:\n",
        "    pinecone.delete_index(INDEX_NAME)\n",
        "print(INDEX_NAME)\n",
        "\n",
        "# Creating a serverless index\n",
        "pinecone.create_index(\n",
        "    name = INDEX_NAME,\n",
        "    dimension = model.get_sentence_embedding_dimension(),\n",
        "    metric = 'cosine',\n",
        "    spec = ServerlessSpec(cloud='aws', region='us-east-1')) #\n",
        "\n",
        "index = pinecone.Index(INDEX_NAME)\n",
        "print(index)"
      ],
      "metadata": {
        "id": "7iJeuj-Q4FM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Embeddings and Upsert to Pinecone"
      ],
      "metadata": {
        "id": "t0Ub94kr4akg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=200\n",
        "vector_limit=10000\n",
        "\n",
        "questions = question[:vector_limit]\n",
        "\n",
        "\n",
        "for i in tqdm(range(0, len(questions), batch_size)):\n",
        "    # find end of batch\n",
        "    i_end = min(i+batch_size, len(questions))\n",
        "    # create IDs batch\n",
        "    ids = [str(x) for x in range(i, i_end)]\n",
        "    # create metadata batch\n",
        "    metadatas = [{'text': text} for text in questions[i:i_end]]\n",
        "    # create embeddings\n",
        "    xc = model.encode(questions[i:i_end])\n",
        "    # create records list for upsert\n",
        "    records = zip(ids, xc, metadatas)\n",
        "    # upsert to Pinecone\n",
        "    index.upsert(vectors=records)"
      ],
      "metadata": {
        "id": "n53UqH_p4djS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index.describe_index_stats()"
      ],
      "metadata": {
        "id": "akA45ZIV4hbe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run your query"
      ],
      "metadata": {
        "id": "C6JraJWP4ian"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# small helper function so we can repeat queries later\n",
        "def run_query(query):\n",
        "  embedding = model.encode(query).tolist()\n",
        "  results = index.query(top_k=10,\n",
        "                        vector=embedding,\n",
        "                        include_metadata=True,\n",
        "                        include_values=False)\n",
        "  for result in results['matches']:\n",
        "    print(f\"{round(result['score'], 2)}: {result['metadata']['text']}\")"
      ],
      "metadata": {
        "id": "u65TLni44mDw"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'which city has the highest population in the world?'\n",
        "run_query(query)"
      ],
      "metadata": {
        "id": "h43-FMdo4nQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "\n",
        "---\n",
        "\n",
        "## Demo 6: RAG with images and text using Pinecone"
      ],
      "metadata": {
        "id": "CK3m_XETQgbn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In this example, we will search with both images and text.\n",
        "- The idea is still the same. You embed images and texts and then upend to the database."
      ],
      "metadata": {
        "id": "z5rxIHYIQAPO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Pinecone"
      ],
      "metadata": {
        "id": "yBau3BzFQZOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone = Pinecone(api_key=userdata.get('pinecone_key'))\n",
        "INDEX_NAME = 'test1-2-16-2025'\n",
        "\n",
        "# Cleaning up the index\n",
        "if INDEX_NAME in [index.name for index in pinecone.list_indexes()]:\n",
        "    pinecone.delete_index(INDEX_NAME)\n",
        "print(INDEX_NAME)\n",
        "\n",
        "# Creating a serverless index\n",
        "pinecone.create_index(\n",
        "    name = INDEX_NAME,\n",
        "    dimension =512,\n",
        "    metric = 'dotproduct',\n",
        "    spec = ServerlessSpec(cloud='aws', region='us-east-1')) #\n",
        "\n",
        "index = pinecone.Index(INDEX_NAME)\n",
        "print(index)"
      ],
      "metadata": {
        "id": "V2EZcwJ2QkY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fashion = load_dataset(\n",
        "    \"ashraq/fashion-product-images-small\",\n",
        "    split=\"train\"\n",
        ")\n",
        "fashion"
      ],
      "metadata": {
        "id": "-3wEJRqoRLBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = fashion['image']\n",
        "metadata = fashion.remove_columns('image')\n",
        "images[900]"
      ],
      "metadata": {
        "id": "9ATAyB6LRM3v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "5de178b1-2e84-41d7-d8cd-b9a1df7da648"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=60x80>"
            ],
            "image/png": "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\n",
            "image/jpeg": "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\n"
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metadata = metadata.to_pandas()\n",
        "metadata.head()"
      ],
      "metadata": {
        "id": "yk4WYY1AROFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the Sparse Vector Using BM25"
      ],
      "metadata": {
        "id": "J8lTN4tkRQCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pinecone_text"
      ],
      "metadata": {
        "id": "FGxN7BaWRbzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "6xjYhWjtCj1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone_text.sparse import BM25Encoder\n",
        "\n",
        "bm25 = BM25Encoder()\n",
        "bm25.fit(metadata['productDisplayName'])\n",
        "metadata['productDisplayName'][0]"
      ],
      "metadata": {
        "id": "Gb5veEbcRTF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bm25.encode_queries(metadata['productDisplayName'][0])\n",
        "bm25.encode_documents(metadata['productDisplayName'][0])"
      ],
      "metadata": {
        "id": "HCfML205RiEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the Dense Vector Using CLIP"
      ],
      "metadata": {
        "id": "toBBd0BdRjXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer('sentence-transformers/clip-ViT-B-32', device=device)\n",
        "model\n",
        "dense_vec = model.encode([metadata['productDisplayName'][0]])\n",
        "dense_vec.shape"
      ],
      "metadata": {
        "id": "fK_jApKCRlUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(fashion)"
      ],
      "metadata": {
        "id": "ahplkFsdRmTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Embeddings Using Sparse and Dense"
      ],
      "metadata": {
        "id": "EhqS9VIkRtWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "fashion_data_num = 1000\n",
        "\n",
        "for i in tqdm(range(0, min(fashion_data_num,len(fashion)), batch_size)):\n",
        "    # find end of batch\n",
        "    i_end = min(i+batch_size, len(fashion))\n",
        "    # extract metadata batch\n",
        "    meta_batch = metadata.iloc[i:i_end]\n",
        "    meta_dict = meta_batch.to_dict(orient=\"records\")\n",
        "    # concatinate all metadata field except for id and year to form a single string\n",
        "    meta_batch = [\" \".join(x) for x in meta_batch.loc[:, ~meta_batch.columns.isin(['id', 'year'])].values.tolist()]\n",
        "    # extract image batch\n",
        "    img_batch = images[i:i_end]\n",
        "    # create sparse BM25 vectors\n",
        "    sparse_embeds = bm25.encode_documents([text for text in meta_batch])\n",
        "    # create dense vectors\n",
        "    dense_embeds = model.encode(img_batch).tolist()\n",
        "    # create unique IDs\n",
        "    ids = [str(x) for x in range(i, i_end)]\n",
        "\n",
        "    upserts = []\n",
        "    # loop through the data and create dictionaries for uploading documents to pinecone index\n",
        "    for _id, sparse, dense, meta in zip(ids, sparse_embeds, dense_embeds, meta_dict):\n",
        "        upserts.append({\n",
        "            'id': _id,\n",
        "            'sparse_values': sparse,\n",
        "            'values': dense,\n",
        "            'metadata': meta\n",
        "        })\n",
        "    # upload the documents to the new hybrid index\n",
        "    index.upsert(upserts)\n",
        "\n",
        "# show index description after uploading the documents\n",
        "index.describe_index_stats()"
      ],
      "metadata": {
        "id": "CvnFlNRkR_Mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Your Query"
      ],
      "metadata": {
        "id": "E6hEFuM_SCiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"dark blue french connection jeans for men\"\n",
        "\n",
        "sparse = bm25.encode_queries(query)\n",
        "dense = model.encode(query).tolist()\n",
        "\n",
        "result = index.query(\n",
        "    top_k=14,\n",
        "    vector=dense,\n",
        "    sparse_vector=sparse,\n",
        "    include_metadata=True\n",
        ")\n",
        "\n",
        "imgs = [images[int(r[\"id\"])] for r in result[\"matches\"]]\n",
        "imgs"
      ],
      "metadata": {
        "id": "1uxDfXh7SDa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.core.display import HTML\n",
        "from io import BytesIO\n",
        "from base64 import b64encode\n",
        "\n",
        "# function to display product images\n",
        "def display_result(image_batch):\n",
        "    figures = []\n",
        "    for img in image_batch:\n",
        "        b = BytesIO()\n",
        "        img.save(b, format='png')\n",
        "        figures.append(f'''\n",
        "            <figure style=\"margin: 5px !important;\">\n",
        "              <img src=\"data:image/png;base64,{b64encode(b.getvalue()).decode('utf-8')}\" style=\"width: 90px; height: 120px\" >\n",
        "            </figure>\n",
        "        ''')\n",
        "    return HTML(data=f'''\n",
        "        <div style=\"display: flex; flex-flow: row wrap; text-align: center;\">\n",
        "        {''.join(figures)}\n",
        "        </div>\n",
        "    ''')"
      ],
      "metadata": {
        "id": "TGcw1M3bSFf9"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_result(imgs)"
      ],
      "metadata": {
        "id": "549dbmrDSGjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scaling the Hybrid Search"
      ],
      "metadata": {
        "id": "3oC6gmAwSII1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hybrid_scale(dense, sparse, alpha: float):\n",
        "    \"\"\"Hybrid vector scaling using a convex combination\n",
        "\n",
        "    alpha * dense + (1 - alpha) * sparse\n",
        "\n",
        "    Args:\n",
        "        dense: Array of floats representing\n",
        "        sparse: a dict of `indices` and `values`\n",
        "        alpha: float between 0 and 1 where 0 == sparse only\n",
        "               and 1 == dense only\n",
        "    \"\"\"\n",
        "    if alpha < 0 or alpha > 1:\n",
        "        raise ValueError(\"Alpha must be between 0 and 1\")\n",
        "    # scale sparse and dense vectors to create hybrid search vecs\n",
        "    hsparse = {\n",
        "        'indices': sparse['indices'],\n",
        "        'values':  [v * (1 - alpha) for v in sparse['values']]\n",
        "    }\n",
        "    hdense = [v * alpha for v in dense]\n",
        "    return hdense, hsparse"
      ],
      "metadata": {
        "id": "ll68MNZ6STLU"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. More Dense"
      ],
      "metadata": {
        "id": "CjjmH0f5SU77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"dark blue french connection jeans for men\"\n",
        "#Closer to 0==more sparse, closer to 1==more dense\n",
        "hdense, hsparse = hybrid_scale(dense, sparse, alpha=1)\n",
        "result = index.query(\n",
        "    top_k=6,\n",
        "    vector=hdense,\n",
        "    sparse_vector=hsparse,\n",
        "    include_metadata=True\n",
        ")\n",
        "imgs = [images[int(r[\"id\"])] for r in result[\"matches\"]]\n",
        "display_result(imgs)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "oeCZJtW-SV1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in result[\"matches\"]:\n",
        "    print(x[\"metadata\"]['productDisplayName'])"
      ],
      "metadata": {
        "id": "vEJj-UgTSX6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. More Sparse"
      ],
      "metadata": {
        "id": "3R7cofgFSYOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"dark blue french connection jeans for men\"\n",
        "#Closer to 0==more sparse, closer to 1==more dense\n",
        "hdense, hsparse = hybrid_scale(dense, sparse, alpha=0)\n",
        "result = index.query(\n",
        "    top_k=6,\n",
        "    vector=hdense,\n",
        "    sparse_vector=hsparse,\n",
        "    include_metadata=True\n",
        ")\n",
        "imgs = [images[int(r[\"id\"])] for r in result[\"matches\"]]\n",
        "display_result(imgs)"
      ],
      "metadata": {
        "id": "iJYJPz3FSZzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in result[\"matches\"]:\n",
        "    print(x[\"metadata\"]['productDisplayName'])"
      ],
      "metadata": {
        "id": "HD-fAE3NSa7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### More Dense or More Sparse?"
      ],
      "metadata": {
        "id": "NsXSZ6m7Se-8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"dark blue french connection jeans for men\"\n",
        "#Closer to 0==more sparse, closer to 1==more dense\n",
        "hdense, hsparse = hybrid_scale(dense, sparse, alpha=0.5)\n",
        "result = index.query(\n",
        "    top_k=6,\n",
        "    vector=hdense,\n",
        "    sparse_vector=hsparse,\n",
        "    include_metadata=True\n",
        ")\n",
        "imgs = [images[int(r[\"id\"])] for r in result[\"matches\"]]\n",
        "display_result(imgs)\n"
      ],
      "metadata": {
        "id": "UPR-7hcJSfrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in result[\"matches\"]:\n",
        "    print(x[\"metadata\"]['productDisplayName'])"
      ],
      "metadata": {
        "id": "HEHg78BxShhh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}