{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMitEezQyNPd8KUY4ekDCN3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yongsa-nut/TU_CN409_GenAI_67_2/blob/main/SSAI_S5_LLM_demos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenizer Demos"
      ],
      "metadata": {
        "id": "SKR1z9bMzLea"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lbz03mtLxBK6"
      },
      "outputs": [],
      "source": [
        "!pip install transformers tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example adapted from Jay Alammar (https://www.youtube.com/watch?v=rT6wVLEDC_w)\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "import tiktoken\n",
        "\n",
        "def show_tokens(text, model_name, print_token_ids = False):\n",
        "    # List of OpenAI models\n",
        "    openai_models = [\n",
        "        \"gpt-4\", \"gpt-3.5-turbo\", \"text-davinci-003\", \"text-davinci-002\",\n",
        "        \"code-davinci-002\", \"code-davinci-001\", \"davinci\", \"curie\", \"babbage\", \"ada\"\n",
        "    ]\n",
        "\n",
        "    if model_name.lower() in [model.lower() for model in openai_models]:\n",
        "        # Use tiktoken for OpenAI models\n",
        "        tokenizer = tiktoken.encoding_for_model(model_name)\n",
        "        token_ids = tokenizer.encode(text)\n",
        "    else:\n",
        "         tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "         token_ids = tokenizer.encode(text)\n",
        "\n",
        "    for t in token_ids:\n",
        "      if print_token_ids:\n",
        "        print(t, end =\" \")\n",
        "      print( '\\x1b[0;30;47m' + tokenizer.decode([t]) + '\\x1b[0m', end = ' ')\n",
        "\n",
        "    print('\\n\\n')\n",
        "\n",
        "    for t in token_ids:\n",
        "      print(t, '\\x1b[0;30;47m' + tokenizer.decode([t]) + '\\x1b[0m')\n",
        "\n",
        "# Example usage\n",
        "text = \"\"\"\n",
        "English and CAPITALIZATION\n",
        "iiiiiiiiiiii\n",
        "à¸ à¸²à¸©à¸²à¹„à¸—à¸¢ à¸„à¸³à¹„à¸—à¸¢ à¸ªà¸§à¸±à¸ªà¸”à¸µ\n",
        "show_tokens False None elif == >= else:\n",
        "Two tab:\"\\t\\t\" Four space: \"    \"\n",
        "12.0*50=600\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "l9Ul585yzRBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Need HF Token: https://huggingface.co/settings/tokens\n",
        "- If you are using Google Colab, you can add it to secret key."
      ],
      "metadata": {
        "id": "bbVmgE80zSwb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_tokens(text,'bert-base-uncased')"
      ],
      "metadata": {
        "id": "6AilZUrNzSda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_tokens(text,'gpt2')"
      ],
      "metadata": {
        "id": "0bR4B6bszewc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_tokens(text,'gpt-4')"
      ],
      "metadata": {
        "id": "f3VW78Izzfs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- For gemma models, need to login and get the access first here (https://huggingface.co/google/gemma-2-9b)\n",
        "\n",
        "- Gemma 2: https://huggingface.co/google/gemma-2-9b\n",
        "- Gemma 3: https://huggingface.co/google/gemma-3-12b-it"
      ],
      "metadata": {
        "id": "5yYcTAFIzhUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "HDMIyBHpzg1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_tokens(text,'google/gemma-2-9b')"
      ],
      "metadata": {
        "id": "bmU-Uc1RzoIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_tokens(text,'google/gemma-3-12b-it')"
      ],
      "metadata": {
        "id": "xm0n6H7GzpAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# API Demo"
      ],
      "metadata": {
        "id": "qkFZvBLfzONF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import json\n",
        "from google.colab import userdata\n",
        "\n",
        "llm = OpenAI(\n",
        "   api_key='sk-Ra57yuyDq7UAQXRRr93SW3oXN1nPZRhFu3MosMr6In05BfY5',   # Insert your API key here\n",
        "   base_url='https://api.opentyphoon.ai/v1' # Use this url to access Typhoon models\n",
        ")"
      ],
      "metadata": {
        "id": "UXyLS-I2zPI_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = llm.chat.completions.create(\n",
        "    model=\"typhoon-v2-8b-instruct\",         # Selected Typhoon model\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Hello how are you doing today?\"\n",
        "        }\n",
        "    ]\n",
        ")\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ickdskWDzFBj",
        "outputId": "b67c165b-065a-4b97-b6ed-409d1a707792"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I'm doing well, thank you for asking. How about you?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(\n",
        "  base_url=\"https://openrouter.ai/api/v1\",\n",
        "  api_key=userdata.get('openrouter'),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOiaXVYezvKt",
        "outputId": "4abfdf96-c995-4acb-d0a6-a671653a689d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I assist you today? ðŸ˜Š\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Hello!\"\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"qwen/qwen3-14b:free\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": prompt\n",
        "    }\n",
        "  ]\n",
        ")\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "nC5HRVpf0wYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic chat loop\n",
        "msg_history = []\n",
        "system_prompt = \"Be nice\"\n",
        "msg_history.append({'role':'system',\n",
        "                    'content':system_prompt})\n"
      ],
      "metadata": {
        "id": "89qrmBtL0zCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Engineering Demo"
      ],
      "metadata": {
        "id": "mHmPYdxc0eZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gen_response(user_prompt, system_prompt=\"\", temperature=0):\n",
        "  completion = client.chat.completions.create(\n",
        "    model=\"qwen/qwen3-14b:free\",\n",
        "    messages=[ {\"role\": \"system\",\"content\": system_prompt},\n",
        "               {\"role\": \"user\",\"content\": user_prompt} ]\n",
        "  )\n",
        "  return completion.choices[0].message.content\n",
        "\n",
        "gen_response(\"Hello\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3LyBqJCB2-6Q",
        "outputId": "30326364-862e-4b04-adfd-51e3e112eca7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello! How can I assist you today? ðŸ˜Š'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1** Get the model to count to three"
      ],
      "metadata": {
        "id": "XRV7wmTQ27iq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen_response(\"Count from one to three\")"
      ],
      "metadata": {
        "id": "YuWnEHQ30g5j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "175835a0-bfed-4077-d5ba-f08a935bac6d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1, 2, 3.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** Modify the system prompt to make **the model respond like it's a 3 year old child**."
      ],
      "metadata": {
        "id": "uwgCn-c53ioE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\n",
        "prompt = \"How big is the sky?\"\n",
        "gen_response(prompt, system_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "uLogiqiW3lOz",
        "outputId": "a96f4cf8-8dde-4b18-ea9a-8c4beec77d5c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The concept of \"how big the sky is\" depends on what you mean by \"sky,\" as it can refer to different things:\\n\\n1. **The Atmosphere (Visible Sky):**  \\n   - The *sky* you see (the blue dome over your head) is part of Earth\\'s **atmosphere**, which extends about **100 km (62 miles)** above the surface.  \\n   - This includes layers like the troposphere (weather), stratosphere (ozone layer), and exosphere (where the atmosphere merges into space). However, the atmosphere gradually thins and doesn\\'t have a strict boundaryâ€”it becomes space at the **KÃ¡rmÃ¡n line (100 km)**, used as the starting point for space exploration.\\n\\n2. **The Celestial Sky (Space and Beyond):**  \\n   - If you\\'re thinking of the **celestial sky** (stars, planets, galaxies), thatâ€™s not limited to Earthâ€™s atmosphere. It encompasses the **entire observable universe**, which is about **93 billion light-years in diameter** (and possibly infinite).  \\n   - The \"sky\" you see at night is a **celestial sphere**â€”a conceptual model of stars and objects arranged in a 360-degree dome around Earth, but this is a projection of their positions relative to us.\\n\\n3. **Perception vs. Reality:**  \\n   - From Earth\\'s surface, the sky appears as an unbounded dome (a hemisphere), but this is an illusion due to perspective. In reality, the atmosphere is a finite layer, and whatâ€™s beyond it (space) is vastly larger.\\n\\n**In short:**  \\n- The **atmospheric sky** is ~100 km tall.  \\n- The **celestial sky** (space and the universe) is *immense*â€”vastly beyond human measurement or imagination.  \\n- The sky as we see it is both a **finite layer** of gas and a **window into the infinite cosmos**.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3** Modify the basketball player prompt so that the model doesn't equivocate at all and responds with ONLY the name of one specific player, with no other words or punctuation."
      ],
      "metadata": {
        "id": "9KxzhvNf3u6l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Who is the best basketball player of all time?\"\n",
        "print(gen_response(prompt))"
      ],
      "metadata": {
        "id": "P9rTnzoE3_st"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4** Modify the prompt so that the model responds with as long a response as you can muster. The response should be over 800 words."
      ],
      "metadata": {
        "id": "YO8wg20D4Imw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"Can you write me a story?\"\n",
        "response = gen_response(prompt)\n",
        "print(f\"Number of words = {len(response.split())}\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "EO4gqJLI4ISZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5**: In this exercise, we'll be instructing the model to sort emails into the following categories:\n",
        "\n",
        "* (A) Pre-sale question\n",
        "* (B) Broken or defective item\n",
        "* (C) Billing question\n",
        "* (D) Other (please explain)\n",
        "\n",
        "For the first part of the exercise, change the prompt below to **make the model output the correct classification and ONLY the classification**. Your answer needs to include the letter (A - D) of the correct choice, with the parentheses, as well as the name of the category.\n",
        "\n",
        "Extra: try giving the model examples.\n"
      ],
      "metadata": {
        "id": "ZKGkMYZH4UXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Modify this!\n",
        "prompt = \"\"\"Please classify this email as either green or blue: {{EMAIL}}\n",
        "\"\"\"\n",
        "\n",
        "# Hint:\n",
        "## 1) How will Claude know what categories you want to use?\n",
        "## 2) Be sure to tell to only include the classification\n",
        "## 3) Consider using prefill to force Claude to only response with the classification immedietely\n",
        "\n",
        "email1 = \"Hi -- My Mixmaster4000 is producing a strange noise when I operate it. It also smells a bit smoky and plasticky, like burning electronics.  I need a replacement.\"\n",
        "email2 = \"Can I use my Mixmaster 4000 to mix paint, or is it only meant for mixing food?\"\n",
        "email3 = \"I HAVE BEEN WAITING 4 MONTHS FOR MY MONTHLY CHARGES TO END AFTER CANCELLING!!  WTF IS GOING ON???\"\n",
        "email4 = \"How did I get here I am not good with computer.  Halp.\"\n",
        "\n",
        "print(gen_response(prompt.format(EMAIL=email1))) # The answer is B\n",
        "print(gen_response(prompt.format(EMAIL=email2))) # The answer is D or A\n",
        "print(gen_response(prompt.format(EMAIL=email3))) # The answer is C\n",
        "print(gen_response(prompt.format(EMAIL=email4))) # The answer is D"
      ],
      "metadata": {
        "id": "JKfE4s5J4U4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reasoning Demo"
      ],
      "metadata": {
        "id": "4ddn5dAF5xBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"What is 1+2+3+4?\"\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"qwen/qwen3-14b:free\",\n",
        "  messages=[\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": prompt\n",
        "    }\n",
        "  ]\n",
        ")\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "VQutsSK_5yOD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "858ed7f1-39f7-4e11-b30d-e5810a5fd00c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sum of 1 + 2 + 3 + 4 is calculated as follows:\n",
            "\n",
            "1. **Direct Addition**:\n",
            "   - Start with $1 + 2 = 3$.\n",
            "   - Next, add $3 + 3 = 6$.\n",
            "   - Finally, add $6 + 4 = 10$.\n",
            "\n",
            "2. **Grouping Strategy**:\n",
            "   - Pair $1 + 4 = 5$ and $2 + 3 = 5$.\n",
            "   - Then, $5 + 5 = 10$.\n",
            "\n",
            "3. **Arithmetic Series Formula**:\n",
            "   - For consecutive integers from 1 to $n$, the sum is $\\frac{n(n + 1)}{2}$.\n",
            "   - Here, $n = 4$, so $\\frac{4 \\times 5}{2} = \\frac{20}{2} = 10$.\n",
            "\n",
            "All methods confirm the result. \n",
            "\n",
            "**Answer:** $1 + 2 + 3 + 4 = \\boxed{10}$\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWdrgw1510Ag",
        "outputId": "0b812fa5-d354-427e-d29c-8be294227f0c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='gen-1747159800-ZcZgMAuuXaP4wQrLT7UP', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The sum of 1 + 2 + 3 + 4 is calculated as follows:\\n\\n1. **Direct Addition**:\\n   - Start with $1 + 2 = 3$.\\n   - Next, add $3 + 3 = 6$.\\n   - Finally, add $6 + 4 = 10$.\\n\\n2. **Grouping Strategy**:\\n   - Pair $1 + 4 = 5$ and $2 + 3 = 5$.\\n   - Then, $5 + 5 = 10$.\\n\\n3. **Arithmetic Series Formula**:\\n   - For consecutive integers from 1 to $n$, the sum is $\\\\frac{n(n + 1)}{2}$.\\n   - Here, $n = 4$, so $\\\\frac{4 \\\\times 5}{2} = \\\\frac{20}{2} = 10$.\\n\\nAll methods confirm the result. \\n\\n**Answer:** $1 + 2 + 3 + 4 = \\\\boxed{10}$', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, reasoning=\"Okay, I need to figure out what 1 + 2 + 3 + 4 is. Let me start by recalling how addition works. Adding numbers together means combining their quantities. So, starting with the first two numbers: 1 + 2. That should be 3, right? Because one plus two more makes three.\\n\\nNext, I have to add the next number, which is 3. So taking the previous result of 3 and adding 3 to it. Hmm, 3 + 3 is 6. Now, moving on to the last number, which is 4. Adding that to the current total of 6. So 6 + 4. Let me check that again. Six plus four... that's ten. Wait, is that correct? Let me verify step by step.\\n\\nAlternatively, maybe I can add them in a different order to cross-verify. Let's see: 1 + 2 is 3, then 3 + 3 is 6, and 6 + 4 is 10. Yeah, that seems right. Another way to think about it is grouping numbers to make the addition easier. For example, adding 1 and 4 first, which gives 5, and then adding 2 and 3, which is 5. Then, 5 + 5 is 10. That's another method, and it still leads to the same answer. \\n\\nWait, is there a formula for the sum of consecutive numbers? I remember something about arithmetic series. The formula is (n(n + 1))/2, where n is the last number. In this case, n is 4. Let me apply that. (4 * 5)/2 = 20/2 = 10. That matches the previous results. \\n\\nSo all the methods I triedâ€”direct addition, grouping, and the arithmetic series formulaâ€”give me the same result, which is 10. I don't see any mistakes in my calculations. Each step checks out, and the different approaches confirm that the sum is indeed 10. I think that's solid.\\n\"), native_finish_reason='stop')], created=1747159800, model='qwen/qwen3-14b:free', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=662, prompt_tokens=19, total_tokens=681, completion_tokens_details=None, prompt_tokens_details=None), provider='Chutes')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tool Uses"
      ],
      "metadata": {
        "id": "2dbwsAJZ0hHE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 1: Using a Calculator Tool"
      ],
      "metadata": {
        "id": "W6vgLoiS578H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup a simple calculator tool\n",
        "- We will simply create a function to do a simple arthmetic calculation.\n",
        "- This function is for demonstration only. The use of `eval` is not recommended."
      ],
      "metadata": {
        "id": "FUDKQrDD5-Ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def calculate(expression):\n",
        "    # Remove any non-digit or non-operator characters from the expression\n",
        "    expression = re.sub(r'[^0-9+\\-*/().]', '', expression)\n",
        "\n",
        "    try:\n",
        "        # Evaluate the expression using the built-in eval() function\n",
        "        result = eval(expression)\n",
        "        return str(result)\n",
        "    except (SyntaxError, ZeroDivisionError, NameError, TypeError, OverflowError):\n",
        "        return \"Error: Invalid expression\"\n",
        "\n",
        "# Claude version\n",
        "tools = [\n",
        "    {\n",
        "        \"name\": \"calculator\",\n",
        "        \"description\": \"A simple calculator that performs basic arithmetic operations.\",\n",
        "        \"input_schema\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"expression\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The mathematical expression to evaluate (e.g., '2 + 3 * 4').\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"expression\"]\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "# OpenAI (Typhoon) version\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"calculator\",\n",
        "            \"description\": \"A simple calculator that performs basic arithmetic operations.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"expression\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The mathematical expression to evaluate (e.g., '2 + 3 * 4').\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"expression\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "8LijQeI75_Mi"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"What is the result of 1,000 * 9,343,116?\"},\n",
        "    ]\n",
        "\n",
        "response = llm.chat.completions.create(\n",
        "    model=\"typhoon-v2-8b-instruct\",     # Selected Typhoon model\n",
        "    messages=messages,                  # Message history\n",
        "    tools=tools,                        # Tools\n",
        ")\n",
        "\n",
        "llm_response = response.choices[0].message\n",
        "print(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_Yw96dhG7P6",
        "outputId": "7c5ea797-4c8c-4ec3-d036-0642592d5d32"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='{\\n\"tool_calls\": [\\n    {\"name\": \"calculator\", \"arguments\": {\"expression\": \"1000 * 9343116\"}}\\n]}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='bb173d67-f58c-4b86-9ffb-875cb98d0e80', function=Function(arguments='{\"expression\": \"1000 * 9343116\"}', name='calculator'), type='function')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQCGHPBYHLkZ",
        "outputId": "568228d1-176b-4d98-92ae-6399a561161f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='ntweYC6-57nCBj-93f66574bbcb3231', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\\n\"tool_calls\": [\\n    {\"name\": \"calculator\", \"arguments\": {\"expression\": \"1000 * 9343116\"}}\\n]}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='bb173d67-f58c-4b86-9ffb-875cb98d0e80', function=Function(arguments='{\"expression\": \"1000 * 9343116\"}', name='calculator'), type='function')]))], created=1747183775, model='typhoon-v2-8b-instruct', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=30, prompt_tokens=338, total_tokens=368, completion_tokens_details=None, prompt_tokens_details=None), prompt=[], duration=2.25516)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Use tool"
      ],
      "metadata": {
        "id": "5jke4116HQxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for tool_call in llm_response.tool_calls:\n",
        "\n",
        "    # Obtain the name and arguments from tool call message\n",
        "    name = tool_call.function.name\n",
        "    arguments = json.loads(tool_call.function.arguments)\n",
        "    expression = arguments['expression']\n",
        "    tool_result = calculate(expression)\n",
        "\n",
        "    print(tool_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SI8hgbUO6CCh",
        "outputId": "8d347613-3d1d-4765-d742-4e833e30c47e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9343116000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create a tool result message"
      ],
      "metadata": {
        "id": "6uUyjHT2IH2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tool_result = {\n",
        "        \"role\" : \"tool\",\n",
        "         # Convert to string\n",
        "         \"content\" : json.dumps({\n",
        "            \"name\": name,\n",
        "            \"arguments\": arguments,\n",
        "            \"results\": tool_result\n",
        "            }\n",
        "         )\n",
        "}\n",
        "\n",
        "# Add tool call and tool result to messages\n",
        "messages.append(response.choices[0].message) # LLM response including tool call message\n",
        "messages.append(tool_result)"
      ],
      "metadata": {
        "id": "qUAKFhxLIKgY"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztRaelSgIWCX",
        "outputId": "39b80d94-6b62-4e55-b2b2-c49a18e280ea"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'user', 'content': 'What is the result of 1,000 * 9,343,116?'},\n",
              " ChatCompletionMessage(content='{\\n\"tool_calls\": [\\n    {\"name\": \"calculator\", \"arguments\": {\"expression\": \"1000 * 9343116\"}}\\n]}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='2d9274ae-706e-4122-8b7a-2019daeb4294', function=Function(arguments='{\"expression\": \"1000 * 9343116\"}', name='calculator'), type='function')]),\n",
              " {'role': 'tool',\n",
              "  'content': '{\"name\": \"calculator\", \"arguments\": {\"expression\": \"1000 * 9343116\"}, \"results\": \"9343116000\"}'}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_response = llm.chat.completions.create(\n",
        "    model=\"typhoon-v2-8b-instruct\",     # Selected Typhoon model\n",
        "    messages=messages,                  # Message history\n",
        "    tools=tools,                        # Tool\n",
        ")\n",
        "print(final_response.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jXBEv9DIfPr",
        "outputId": "6fdbb3de-d869-4c59-d3ca-bf5fdf99045e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The result of 1,000 * 9,343,116 is 9,343,116,000.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNF5p4njJYJ0",
        "outputId": "44269a3f-14ae-4617-de3f-0588e4a54d28"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='ntwUem5-57nCBj-93f6365eb89ca077', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The result of 1,000 * 9,343,116 is 9,343,116,000.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1747181846, model='typhoon-v2-8b-instruct', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=25, prompt_tokens=411, total_tokens=436, completion_tokens_details=None, prompt_tokens_details=None), prompt=[], duration=1.91086)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example 2: A Customer Service Agent\n",
        "- We will create a mockup customer service agent that can look up customer information, retrieve order details, and cancel orders on behalf of the custome."
      ],
      "metadata": {
        "id": "HgaXO0qw6Px7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step1:  Simulate synthetic tool responses"
      ],
      "metadata": {
        "id": "vBzOJ8cK6RPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_customer_info(customer_id):\n",
        "    # Simulated customer data\n",
        "    customers = {\n",
        "        \"C1\": {\"name\": \"John Doe\", \"email\": \"john@example.com\", \"phone\": \"123-456-7890\"},\n",
        "        \"C2\": {\"name\": \"Jane Smith\", \"email\": \"jane@example.com\", \"phone\": \"987-654-3210\"}\n",
        "    }\n",
        "    return customers.get(customer_id, \"Customer not found\")\n",
        "\n",
        "def get_order_details(order_id):\n",
        "    # Simulated order data\n",
        "    orders = {\n",
        "        \"O1\": {\"id\": \"O1\", \"product\": \"Widget A\", \"quantity\": 2, \"price\": 19.99, \"status\": \"Shipped\"},\n",
        "        \"O2\": {\"id\": \"O2\", \"product\": \"Gadget B\", \"quantity\": 1, \"price\": 49.99, \"status\": \"Processing\"}\n",
        "    }\n",
        "    return orders.get(order_id, \"Order not found\")\n",
        "\n",
        "def cancel_order(order_id):\n",
        "    # Simulated order cancellation\n",
        "    if order_id in [\"O1\", \"O2\"]:\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "metadata": {
        "id": "7aEgg9cg6SQz"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Define the client-side tools"
      ],
      "metadata": {
        "id": "5Xik3hPS6Tjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\":{\n",
        "            \"name\": \"get_customer_info\",\n",
        "            \"description\": \"Retrieves customer information based on their customer ID. Returns the customer's name, email, and phone number.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"customer_id\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The unique identifier for the customer.\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"customer_id\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\":{\n",
        "            \"name\": \"get_order_details\",\n",
        "            \"description\": \"Retrieves the details of a specific order based on the order ID. Returns the order ID, product name, quantity, price, and order status.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"order_id\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The unique identifier for the order.\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"order_id\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\":{\n",
        "            \"name\": \"cancel_order\",\n",
        "            \"description\": \"Cancels an order based on the provided order ID. Returns a confirmation message if the cancellation is successful.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"order_id\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The unique identifier for the order to be cancelled.\"\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"order_id\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "v_QGpDQF6UfP"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Process tool calls and return results"
      ],
      "metadata": {
        "id": "ZdnR-1KD6V-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# a function to process the tool calls made by Claude and return the appropriate results\n",
        "def process_tool_call(tool_name, tool_input):\n",
        "    if tool_name == \"get_customer_info\":\n",
        "        return get_customer_info(tool_input[\"customer_id\"])\n",
        "    elif tool_name == \"get_order_details\":\n",
        "        return get_order_details(tool_input[\"order_id\"])\n",
        "    elif tool_name == \"cancel_order\":\n",
        "        return cancel_order(tool_input[\"order_id\"])"
      ],
      "metadata": {
        "id": "GKIPqRvN6Xck"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Interact with the chatbot"
      ],
      "metadata": {
        "id": "CzxSrfss6aUA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def chatbot_interaction(user_message):\n",
        "    print(f\"\\n{'='*50}\\nUser Message: {user_message}\\n{'='*50}\")\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\":\"You are a helpful customer support agent. You should use tools to answer questions.\"},\n",
        "        {\"role\": \"user\", \"content\": user_message}\n",
        "    ]\n",
        "    # Get the initial response\n",
        "    response = llm.chat.completions.create(\n",
        "        model=\"typhoon-v2-8b-instruct\",     # Selected Typhoon model\n",
        "        messages=messages,                  # Message history\n",
        "        tools=tools,                        # Tool\n",
        "        temperature = 0                     # set temp = 0 so that's the answer is mostly deterministic\n",
        "    )\n",
        "    llm_response = response.choices[0].message\n",
        "    print(f\"\\nInitial Response:\")\n",
        "    print(f\"Content: {llm_response}\")\n",
        "\n",
        "    for tool_call in llm_response.tool_calls:\n",
        "\n",
        "        # Obtain the name and arguments from tool call message\n",
        "        tool_name = tool_call.function.name\n",
        "        tool_arguments = json.loads(tool_call.function.arguments)\n",
        "        print(f\"\\nTool Used: {tool_name}\")\n",
        "        print(f\"Tool arguments:\")\n",
        "        print(tool_arguments)\n",
        "\n",
        "        tool_result = process_tool_call(tool_name, tool_arguments)\n",
        "        print(f\"\\nTool Result:\")\n",
        "        print(tool_result)\n",
        "\n",
        "        # Construct tool result messages\n",
        "        tool_result = {\n",
        "            \"role\" : \"tool\",\n",
        "            # Convert to string\n",
        "            \"content\" : json.dumps({\n",
        "                \"name\": tool_name,\n",
        "                \"arguments\": tool_arguments,\n",
        "                \"results\": str(tool_result)\n",
        "                }\n",
        "            )\n",
        "        }\n",
        "\n",
        "        # Add tool call and tool result to messages\n",
        "        messages.append(llm_response) # LLM response including tool call message\n",
        "        messages.append(tool_result)\n",
        "\n",
        "        response = llm.chat.completions.create(\n",
        "            model=\"typhoon-v2-8b-instruct\",     # Selected Typhoon model\n",
        "            messages=messages,                  # Message history\n",
        "            tools=tools,                        # Tool\n",
        "        )\n",
        "\n",
        "        print(f\"\\nResponse:\")\n",
        "        print(f\"Content: {response.choices[0]}\")\n",
        "\n",
        "    print(f'\\nFinal Response: ')\n",
        "    print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "xc_JcjSE6bI_"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Test the chatbot"
      ],
      "metadata": {
        "id": "qRf2oM8i6cWd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot_interaction(\"Can you tell me the email address for customer C1?\")"
      ],
      "metadata": {
        "id": "vdn6yj1H6dhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot_interaction(\"What is the status of order O2?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ys6cb4LQ6evX",
        "outputId": "2254bb58-7721-4308-b691-fc9ff9c26978"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "User Message: What is the status of order O2?\n",
            "==================================================\n",
            "\n",
            "Initial Response:\n",
            "Content: ChatCompletionMessage(content='{\\n\"tool_calls\": [\\n    {\"name\": \"get_order_details\", \"arguments\": {\"order_id\": \"O2\"}}\\n]}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='be34894f-f32d-401d-bf1e-be3856379e10', function=Function(arguments='{\"order_id\": \"O2\"}', name='get_order_details'), type='function')])\n",
            "\n",
            "Tool Used: get_order_details\n",
            "Tool arguments:\n",
            "{'order_id': 'O2'}\n",
            "\n",
            "Tool Result:\n",
            "{'id': 'O2', 'product': 'Gadget B', 'quantity': 1, 'price': 49.99, 'status': 'Processing'}\n",
            "\n",
            "Response:\n",
            "Content: Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The status of order O2 is Processing.', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))\n",
            "\n",
            "Final Response: \n",
            "The status of order O2 is Processing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot_interaction(\"Please cancel order O1 for me.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LfV1Pc46f7A",
        "outputId": "c3dfbe97-5a6c-4281-93b6-4167c28f2474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "User Message: Please cancel order O1 for me.\n",
            "==================================================\n",
            "\n",
            "Initial Response:\n",
            "Content: ChatCompletionMessage(content='{\\n\"tool_calls\": [\\n    {\"name\": \"cancel_order\", \"arguments\": {\"order_id\": \"O1\"}}\\n]}', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='be7be560-3cb3-4e94-9846-26f4d84a28de', function=Function(arguments='{\"order_id\": \"O1\"}', name='cancel_order'), type='function')])\n",
            "\n",
            "Tool Used: cancel_order\n",
            "Tool arguments:\n",
            "{'order_id': 'O1'}\n",
            "\n",
            "Tool Result:\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agentic Demo\n",
        "\n",
        "Adapted from https://github.com/disler/single-file-agents/blob/main/sfa_duckdb_anthropic_v2.py"
      ],
      "metadata": {
        "id": "3pwon_ua0iVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install anthropic"
      ],
      "metadata": {
        "id": "l3ImsjKU0sQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import duckdb\n",
        "import subprocess\n",
        "import json\n",
        "from typing import List\n",
        "from rich import print\n",
        "from anthropic import Anthropic\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "cYNTfh520tES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#download the data\n",
        "!wget https://github.com/disler/single-file-agents/raw/refs/heads/main/data/analytics.db"
      ],
      "metadata": {
        "id": "SjVhpzGD0t8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to the database\n",
        "DB_PATH = '/content/analytics.db'\n",
        "DB_CONN = duckdb.connect(DB_PATH)"
      ],
      "metadata": {
        "id": "Y25Bvh7e0vCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Database Agent\n",
        "\n",
        "5 tools (functions)\n",
        "- `list_table`: Returns list of available tables in database\n",
        "- `describe_table`: Returns schema info for specified table\n",
        "- `sample_table`: Returns sample rows from specified table, always specify row_sample_size\n",
        "- `run_test_sql_query`: Tests a SQL query and returns results (only visible to agent)\n",
        "- `run_final_sql_query`: Runs the final validated SQL query and shows results to user\n",
        "\n",
        "The agent will keep using tools looking at the result and keep going until it generates accurate queries for the user."
      ],
      "metadata": {
        "id": "KXe5xOfi0zru"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `list_tables`\n",
        "\n",
        "Returns a list of tables in the database. The agent uses this to discover available tables and make informed decisions."
      ],
      "metadata": {
        "id": "SuWR55kp01G6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def list_tables(reasoning: str) -> List[str]:\n",
        "    \"\"\"Returns a list of tables in the database.\n",
        "\n",
        "    The agent uses this to discover available tables and make informed decisions.\n",
        "\n",
        "    Args:\n",
        "        reasoning: Explanation of why we're listing tables relative to user request\n",
        "\n",
        "    Returns:\n",
        "        List of table names as strings\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Use the global connection\n",
        "        result = DB_CONN.execute(\"SELECT name FROM sqlite_master WHERE type='table'\").fetchall()\n",
        "\n",
        "        # Extract table names from the result\n",
        "        table_names = [row[0] for row in result]\n",
        "\n",
        "        print(f\"List Tables Tool - Reasoning: {reasoning}\")\n",
        "        return table_names\n",
        "    except Exception as e:\n",
        "        print(f\"Error listing tables: {str(e)}\")\n",
        "        return []"
      ],
      "metadata": {
        "id": "vWEdlTyq02Db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_tables('Test')"
      ],
      "metadata": {
        "id": "JRe-cNFZ03nD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `describe_table`\n",
        "\n",
        "Returns schema information about the specified table.\n",
        "The agent uses this to understand table structure and available columns."
      ],
      "metadata": {
        "id": "nnn2324p04r_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def describe_table(reasoning: str, table_name: str) -> str:\n",
        "    \"\"\"Returns schema information about the specified table.\n",
        "\n",
        "    The agent uses this to understand table structure and available columns.\n",
        "\n",
        "    Args:\n",
        "        reasoning: Explanation of why we're describing this table\n",
        "        table_name: Name of table to describe\n",
        "\n",
        "    Returns:\n",
        "        String containing table schema information\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Use the global connection to execute DESCRIBE\n",
        "        result = DB_CONN.execute(f\"DESCRIBE {table_name}\").fetchall()\n",
        "\n",
        "        # Convert result to a string - DuckDB's DESCRIBE already returns\n",
        "        # nicely formatted column information\n",
        "        schema_info = \"\\n\".join(str(row) for row in result)\n",
        "\n",
        "        # Log the operation\n",
        "        print(f\"Describe Table Tool - Table: {table_name} - Reasoning: {reasoning}\")\n",
        "        return schema_info\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error describing table: {str(e)}\")\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "ffo7KDQY051n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(describe_table('Test','User'))"
      ],
      "metadata": {
        "id": "8ipbVO-t07JD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "('id', 'UUID', 'YES', None, None, None)\n",
        " â”‚      â”‚      â”‚      â”‚     â”‚     â”‚\n",
        " â”‚      â”‚      â”‚      â”‚     â”‚     â””â”€ 6. Column comment or extra info (None here)\n",
        " â”‚      â”‚      â”‚      â”‚     â””â”€â”€â”€â”€â”€ 5. Column position or other metadata (None here)\n",
        " â”‚      â”‚      â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 4. Default value (None here)\n",
        " â”‚      â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 3. Nullable status ('YES' means column can be NULL)\n",
        " â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 2. Data type (UUID type)\n",
        " â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 1. Column name (id)\n",
        "```"
      ],
      "metadata": {
        "id": "zJrjI2ja09an"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `sample_table`\n",
        "\n",
        "Returns a sample of rows from the specified table.\n",
        "The agent uses this to understand actual data content and patterns."
      ],
      "metadata": {
        "id": "L3JAcOcT0-rA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_table(reasoning: str, table_name: str, row_sample_size: int) -> str:\n",
        "    \"\"\"Returns a sample of rows from the specified table.\n",
        "\n",
        "    The agent uses this to understand actual data content and patterns.\n",
        "\n",
        "    Args:\n",
        "        reasoning: Explanation of why we're sampling this table\n",
        "        table_name: Name of table to sample from\n",
        "        row_sample_size: Number of rows to sample aim for 3-5 rows\n",
        "\n",
        "    Returns:\n",
        "        String containing sample rows in readable format\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Use the global connection to select sample rows\n",
        "        result = DB_CONN.execute(\n",
        "            f\"SELECT * FROM {table_name} LIMIT {row_sample_size}\"\n",
        "        ).fetchall()\n",
        "\n",
        "        # Get column names for context\n",
        "        columns = DB_CONN.execute(\n",
        "            f\"SELECT column_name FROM information_schema.columns WHERE table_name = '{table_name}'\"\n",
        "        ).fetchall()\n",
        "        column_names = [col[0] for col in columns]\n",
        "\n",
        "        # Format the output with column names and data\n",
        "        header = str(column_names)\n",
        "        rows = [str(row) for row in result]\n",
        "\n",
        "        sample_data = header + \"\\n\" + \"\\n\".join(rows)\n",
        "\n",
        "        print(f\"Sample Table Tool - Table: {table_name} - Rows: {row_sample_size} - Reasoning: {reasoning}\")\n",
        "\n",
        "        return sample_data\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error sampling table: {str(e)}\")\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "ExdEPzA60_gx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample_table('Test','User',5))"
      ],
      "metadata": {
        "id": "YhMwER5s1Bv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `run_test_sql_query`\n",
        "\n",
        "Executes a test SQL query and returns results.\n",
        "\n",
        "The agent uses this to validate queries before finalizing them. Results are only shown to the agent, not the user."
      ],
      "metadata": {
        "id": "2XRJ5_291A1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_test_sql_query(reasoning: str, sql_query: str) -> str:\n",
        "    \"\"\"Executes a test SQL query and returns results.\n",
        "\n",
        "    The agent uses this to validate queries before finalizing them.\n",
        "    Results are only shown to the agent, not the user.\n",
        "\n",
        "    Args:\n",
        "        reasoning: Explanation of why we're running this test query\n",
        "        sql_query: The SQL query to test\n",
        "\n",
        "    Returns:\n",
        "        Query results as a string\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Use the global connection to execute the query\n",
        "        result = DB_CONN.execute(sql_query).fetchall()\n",
        "\n",
        "        # Convert result to a simple string representation\n",
        "        # For educational purposes, keeping the output straightforward\n",
        "        output = \"\\n\".join(str(row) for row in result)\n",
        "\n",
        "        print(f\"Test Query Tool - Reasoning: {reasoning}\")\n",
        "        print(f\"Query: {sql_query}\")\n",
        "\n",
        "        return output\n",
        "    except Exception as e:\n",
        "        print(f\"Error running test query: {str(e)}\")\n",
        "        return str(e)"
      ],
      "metadata": {
        "id": "Sp3tTPeI1CuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(run_test_sql_query('Test','SELECT * FROM User WHERE AGE > 50'))"
      ],
      "metadata": {
        "id": "-CHezM881ECy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `run_final_sql_query`"
      ],
      "metadata": {
        "id": "WqxFbrXr1F4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_final_sql_query(reasoning: str, sql_query: str) -> str:\n",
        "    \"\"\"Executes the final SQL query and returns results to user.\n",
        "\n",
        "    This is the last tool call the agent should make after validating the query.\n",
        "\n",
        "    Args:\n",
        "        reasoning: Final explanation of how this query satisfies user request\n",
        "        sql_query: The validated SQL query to run\n",
        "\n",
        "    Returns:\n",
        "        Query results as a string\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Use the global connection to execute the query\n",
        "        result = DB_CONN.execute(sql_query).fetchall()\n",
        "\n",
        "        # Convert result to a string - format is a simple representation of each row\n",
        "        results_str = \"\\n\".join(str(row) for row in result)\n",
        "\n",
        "        # Use regular print with simple formatting\n",
        "        print(f\"Final Query Tool\\nReasoning: {reasoning}\\nQuery: {sql_query}\")\n",
        "\n",
        "        return results_str\n",
        "    except Exception as e:\n",
        "        print(f\"Error running final query: {str(e)}\")\n",
        "        return str(e)"
      ],
      "metadata": {
        "id": "J7xURBWI1G_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(run_final_sql_query('Test','SELECT * FROM User WHERE AGE > 50'))"
      ],
      "metadata": {
        "id": "gUWytum21J-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Tools"
      ],
      "metadata": {
        "id": "xmeryKx-1Lgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools=[\n",
        "        {\n",
        "            \"name\": \"list_tables\",\n",
        "            \"description\": \"Returns a list of available tables in database\",\n",
        "            \"input_schema\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"reasoning\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Explanation for listing tables\",\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"reasoning\"],\n",
        "            },\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"describe_table\",\n",
        "            \"description\": \"Returns schema info for a specified table\",\n",
        "            \"input_schema\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"reasoning\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Why we need to describe this table\",\n",
        "                    },\n",
        "                    \"table_name\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Name of a table to describe\",\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"reasoning\", \"table_name\"],\n",
        "            },\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"sample_table\",\n",
        "            \"description\": \"Returns sample rows from specified table\",\n",
        "            \"input_schema\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"reasoning\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Why we need to sample this table\",\n",
        "                    },\n",
        "                    \"table_name\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Name of table to sample\",\n",
        "                    },\n",
        "                    \"row_sample_size\": {\n",
        "                        \"type\": \"integer\",\n",
        "                        \"description\": \"Number of rows to sample aim for 3-5 rows\",\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"reasoning\", \"table_name\", \"row_sample_size\"],\n",
        "            },\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"run_test_sql_query\",\n",
        "            \"description\": \"Tests a SQL query and returns results (only visible to agent)\",\n",
        "            \"input_schema\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"reasoning\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Why we're testing this specific query\",\n",
        "                    },\n",
        "                    \"sql_query\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The SQL query to test\",\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"reasoning\", \"sql_query\"],\n",
        "            },\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"run_final_sql_query\",\n",
        "            \"description\": \"Runs the final validated SQL query and shows results to user\",\n",
        "            \"input_schema\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"reasoning\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"Final explanation of how query satisfies user request\",\n",
        "                    },\n",
        "                    \"sql_query\": {\n",
        "                        \"type\": \"string\",\n",
        "                        \"description\": \"The validated SQL query to run\",\n",
        "                    },\n",
        "                },\n",
        "                \"required\": [\"reasoning\", \"sql_query\"],\n",
        "            },\n",
        "        },\n",
        "    ]"
      ],
      "metadata": {
        "id": "cxqXtHFd1LMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function calling\n",
        "def call_function(func_name, func_args):\n",
        "\n",
        "    if func_name == \"list_tables\":\n",
        "        result = list_tables(reasoning=func_args[\"reasoning\"])\n",
        "    elif func_name == \"describe_table\":\n",
        "        result = describe_table(\n",
        "            reasoning=func_args[\"reasoning\"],\n",
        "            table_name=func_args[\"table_name\"],\n",
        "        )\n",
        "    elif func_name == \"sample_table\":\n",
        "        result = sample_table(\n",
        "            reasoning=func_args[\"reasoning\"],\n",
        "            table_name=func_args[\"table_name\"],\n",
        "            row_sample_size=func_args[\"row_sample_size\"],\n",
        "        )\n",
        "    elif func_name == \"run_test_sql_query\":\n",
        "        result = run_test_sql_query(\n",
        "            reasoning=func_args[\"reasoning\"],\n",
        "            sql_query=func_args[\"sql_query\"],\n",
        "        )\n",
        "    elif func_name == \"run_final_sql_query\":\n",
        "        result = run_final_sql_query(\n",
        "            reasoning=func_args[\"reasoning\"],\n",
        "            sql_query=func_args[\"sql_query\"],\n",
        "        )\n",
        "    else:\n",
        "        raise Exception(f\"Unknown tool call: {func_name}\")\n",
        "    return result"
      ],
      "metadata": {
        "id": "MPb90K4K1Nur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt\n",
        "\n",
        "**Note**: When you call the Anthropic API with the tools parameter, we construct a special system prompt from the tool definitions, tool configuration, and any user-specified system prompt. The constructed prompt is designed to instruct the model to use the specified tool(s) and provide the necessary context for the tool to operate properly."
      ],
      "metadata": {
        "id": "vTDibLWa1QLf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AGENT_PROMPT = \"\"\"You are a world-class expert at crafting precise DuckDB SQL queries.\n",
        "Your goal is to generate accurate queries that exactly match the user's data needs.\n",
        "\n",
        "<instructions>\n",
        "    - Use the provided tools to explore the database and construct the perfect query.\n",
        "    - Start by listing tables to understand what's available.\n",
        "    - Describe tables to understand their schema and columns.\n",
        "    - Sample tables to see actual data patterns.\n",
        "    - Test queries before finalizing them.\n",
        "    - Only call run_final_sql_query when you're confident the query is perfect.\n",
        "    - Be thorough but efficient with tool usage.\n",
        "    - If you find your run_test_sql_query tool call returns an error or won't satisfy the user request, try to fix the query or try a different query.\n",
        "    - Think step by step about what information you need.\n",
        "    - Be sure to specify every parameter for each tool call.\n",
        "    - Every tool call should have a reasoning parameter which gives you a place to explain why you are calling the tool.\n",
        "</instructions>\n",
        "\n",
        "<user-request>\n",
        "    {{user_request}}\n",
        "</user-request>\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ofZl3KCm1Q_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Agent Loop"
      ],
      "metadata": {
        "id": "wRK0AMYu1Sjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example to test: Show me all users with score above 80"
      ],
      "metadata": {
        "id": "OsIcX0Mp1Vnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = input('Enter query: ')\n",
        "completed_prompt = AGENT_PROMPT.replace(\"{{user_request}}\", user_query)\n",
        "messages = [{\"role\": \"user\", \"content\": completed_prompt}]\n",
        "\n",
        "max_iteration = 15\n",
        "compute_iterations = 0\n",
        "final_result = False\n",
        "\n",
        "# Main agent loop\n",
        "while not final_result:\n",
        "    print(f\"\\n=== Agent Loop {compute_iterations+1}/{max_iteration} ===\")\n",
        "    compute_iterations += 1\n",
        "\n",
        "    if compute_iterations > max_iteration:\n",
        "      print(\"Warning: Reached maximum compute loops without final query\" )\n",
        "      break\n",
        "\n",
        "    # Generate content with tool support\n",
        "    response = client.messages.create(\n",
        "        model=\"claude-3-7-sonnet-20250219\",\n",
        "        max_tokens=1024,\n",
        "        messages=messages,\n",
        "        tools=tools,\n",
        "        tool_choice={\"type\": \"any\"}  # Always force a tool call\n",
        "    )\n",
        "\n",
        "    # Look for tool calls in the response (expecting ToolUseBlock objects)\n",
        "    tool_calls = []\n",
        "    for block in response.content:\n",
        "        if hasattr(block, \"type\") and block.type == \"tool_use\":\n",
        "            tool_calls.append(block)\n",
        "\n",
        "    for tool_call in tool_calls:\n",
        "        tool_use_id = tool_call.id\n",
        "        func_name = tool_call.name\n",
        "        func_args = (tool_call.input)\n",
        "\n",
        "        print(f\"Tool Call: {func_name}({json.dumps(func_args)})\")\n",
        "        messages.append({\"role\": \"assistant\", \"content\": response.content})\n",
        "\n",
        "        try:\n",
        "            result = call_function(func_name, func_args)\n",
        "            if func_name == \"run_final_sql_query\":\n",
        "                print(f\"\\n\\n***** Final Results *****\\n\")\n",
        "                print(result)\n",
        "                final_result = True\n",
        "                break\n",
        "            print(f\"Tool Call Result: {func_name}(...) ->\\n{result}\")\n",
        "\n",
        "            messages.append(\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\n",
        "                            \"type\": \"tool_result\",\n",
        "                            \"tool_use_id\": tool_use_id,\n",
        "                            \"content\": str(result),\n",
        "                        }\n",
        "                    ],\n",
        "                }\n",
        "            )\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"Error executing {func_name}: {str(e)}\"\n",
        "            print(f\"{error_msg}\")\n",
        "            # See info https://docs.anthropic.com/en/docs/build-with-claude/tool-use/overview#troubleshooting-errors\n",
        "            messages.append(\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\n",
        "                            \"type\": \"tool_result\",\n",
        "                            \"tool_use_id\": tool_use_id,\n",
        "                            \"content\": error_msg,\n",
        "                            \"is_error\": True\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            )\n",
        "            continue"
      ],
      "metadata": {
        "id": "pDKpCM4b1WwZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}